{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cf9ffe",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import HTML,clear_output\n",
    "from importlib import reload\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from importData import import_all,generate_diffuse_tether_trajectories\n",
    "import displayData\n",
    "import trajAnalysis\n",
    "import bayesianTools\n",
    "from model_utils import GenerationMode\n",
    "import model\n",
    "from utils import notebook_setup_widgets\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e299fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_steps = 1000\n",
    "N_particle=40\n",
    "\n",
    "dt=1./30\n",
    "T_stick= 200*dt\n",
    "T_unstick= 200*dt\n",
    "D= 0.3333\n",
    "A= D*dt/2\n",
    "\n",
    "df, model_params = tests.generateSynthTrajs(N_steps, N_particle, dt, T_stick, T_unstick, D, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85bd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "X_arr_list = bayesianTools.extract_X_arr_list_from_df(df)\n",
    "dt_list = bayesianTools.extract_dt_list_from_df(df)\n",
    "\n",
    "def costFun(params):\n",
    "    TT_stick,TT_unstick,DD,AA = params\n",
    "#     DD,AA = params\n",
    "#     TT_stick = T_stick\n",
    "#     TT_unstick = T_unstick\n",
    "    t = time.time()\n",
    "    L = bayesianTools.multiple_trajectories_likelihood(X_arr_list, dt_list, TT_stick, TT_unstick, DD, AA,\n",
    "                                     is_parallel=True)\n",
    "    print(\"Params=[{},{},{},{}]; L={}; In {} sec\".format(\n",
    "    np.round(TT_stick,0),np.round(TT_unstick,0),np.round(DD,9),np.round(AA,9),np.round(L,9),np.round(time.time()-t,1)))\n",
    "    return -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed913ee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'A' of type float64\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of get attribute at C:\\repos\\Diffusion\\bayesianTools.py (75)\u001b[0m\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"C:\\Users\\User\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"C:\\Users\\User\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"C:\\Users\\User\\miniconda3\\envs\\diffusion\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 468, in _compile_for_args\n    error_rewrite(e, 'typing')\n  File \"C:\\Users\\User\\miniconda3\\envs\\diffusion\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 409, in error_rewrite\n    raise e.with_traceback(None)\nnumba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'A' of type float64\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of get attribute at C:\\repos\\Diffusion\\bayesianTools.py (75)\u001b[0m\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6972/2746587837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcostFun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mT_stick\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT_unstick\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m   1202\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6972/851985246.py\u001b[0m in \u001b[0;36mcostFun\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     TT_unstick = T_unstick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     L = bayesianTools.multiple_trajectories_likelihood(X_arr_list, dt_list, TT_stick, TT_unstick, DD, AA,\n\u001b[0m\u001b[0;32m     12\u001b[0m                                      is_parallel=True)\n\u001b[0;32m     13\u001b[0m     print(\"Params=[{},{},{},{}]; L={}; In {} sec\".format(\n",
      "\u001b[1;32mC:\\repos\\Diffusion\\bayesianTools.py\u001b[0m in \u001b[0;36mmultiple_trajectories_likelihood\u001b[1;34m(X_arr_list, dt_list, T_stick, T_unstick, D, A, is_parallel)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_parallel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_PROCESSORS_LIMIT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             for n, output in enumerate(executor.map(viterbi_algorithm, X_arr_list, model_params, repeat(False)\n\u001b[0m\u001b[0;32m    215\u001b[0m                                                     )):\n\u001b[0;32m    216\u001b[0m                 \u001b[0mL_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \"\"\"\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\diffusion\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: \u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mUnknown attribute 'A' of type float64\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of get attribute at C:\\repos\\Diffusion\\bayesianTools.py (75)\u001b[0m\n\u001b[1m\nFile \"bayesianTools.py\", line 75:\u001b[0m\n\u001b[1mdef viterbi_algorithm(X_arr, model_params:model.Params, do_backprop=True, ):\n    <source elided>\n    # More parameters\n\u001b[1m    squared_distance_discard_threshold = FORGET_FAR_TETHER_POINTS_THRESHOLD_RATIO * model_params.A  # For the first filter\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "res = scipy.optimize.minimize(costFun, [T_stick*5,T_unstick/4, D*2,A/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242b223",
   "metadata": {},
   "source": [
    "# Import a dataframe\n",
    "\n",
    "## Import experimental data\n",
    "\n",
    "*Note*: The first import after will include reading from .csv and saving to a binary feather file and might take a few minutes.\n",
    "\n",
    "#### Select experiments and/or particles with the widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d2cbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_df = import_all();df = full_df.copy();\n",
    "expSelectWidget,rdmEnableWidget,rdmSameVideoWidget,keepStuckWidget,rdmSelectionWidget,specificEnableWidget,specificParticleSelectionWidget,buttonFilterWidget,filterDataframesFun=notebook_setup_widgets(widgets)\n",
    "expSelectWidget.options = full_df.experiment.unique(); specificParticleSelectionWidget.min = full_df.particle.min(); specificParticleSelectionWidget.max = full_df.particle.max(); buttonFilterWidget.on_click(lambda b: filterDataframesFun(full_df,df))    \n",
    "display(expSelectWidget,widgets.HBox((widgets.VBox((rdmEnableWidget,keepStuckWidget)),widgets.VBox((rdmSelectionWidget,rdmSameVideoWidget)))),widgets.HBox((specificEnableWidget,specificParticleSelectionWidget)),buttonFilterWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c02f6",
   "metadata": {},
   "source": [
    "### Alternatively, create a synthetic dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8c3a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_steps = 1000\n",
    "N_particle=10\n",
    "\n",
    "dt=1./30\n",
    "T_stick= 200*dt\n",
    "T_unstick= 200*dt\n",
    "D= 0.3333\n",
    "A= D*dt/5\n",
    "\n",
    "generation_mode=GenerationMode.DONT_FORCE #keep this\n",
    "init_S=None #random\n",
    "do_post_processing=False #calculate some extra statistics, this takes a short while\n",
    "undersample_ratio=0#0.1\n",
    "save_files=False\n",
    "is_parallel=False #relevant only if do_post_processing==True\n",
    "\n",
    "model_params = model.pack_model_params(T_stick,T_unstick,D,A,dt) #for convenience\n",
    "\n",
    "df=generate_diffuse_tether_trajectories(T_stick, T_unstick, D, A, dt, N_steps,  N_particle, init_S,\n",
    "                                     do_post_processing,undersample_ratio, save_files, generation_mode, is_parallel)\n",
    "\n",
    "true_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d23e60",
   "metadata": {},
   "source": [
    "#### Create heatmaps data for Amit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bayesianTools)\n",
    "\n",
    "X_arr_list = bayesianTools.extract_X_arr_list_from_df(df)\n",
    "dt_list = bayesianTools.extract_dt_list_from_df(df)\n",
    "\n",
    "\n",
    "D_arr = np.logspace(-.5,.5,3)*D\n",
    "A_arr = np.logspace(-.5,.5,3)*A\n",
    "L_mat = np.zeros([len(D_arr),len(A_arr)])\n",
    "for n,D_iter in enumerate(D_arr):\n",
    "    for m,A_iter in enumerate(A_arr):\n",
    "        L_mat[n,m]=bayesianTools.multiple_trajectories_likelihood(X_arr_list, dt_list, T_stick, T_unstick, D_iter, A_iter,\n",
    "                                     is_parallel=True)\n",
    "\n",
    "        print([n,m])\n",
    "np.save(\"L_mat\",L_mat)    \n",
    "\n",
    "    \n",
    "reload(bayesianTools)\n",
    "T1_arr = np.logspace(-1.,3.,21)*T_stick\n",
    "T2_arr = np.logspace(-1.,3.,21)*T_unstick\n",
    "L_mat2 = np.zeros([len(T1_arr),len(T2_arr)])\n",
    "for n,T1_iter in enumerate(T1_arr):\n",
    "    for m,T2_iter in enumerate(T2_arr):\n",
    "        L_mat2[n,m]=bayesianTools.multiple_trajectories_likelihood(X_arr_list, dt_list, T1_iter, T2_iter, D, A,\n",
    "                                     is_parallel=True)\n",
    "\n",
    "        print([n,m])\n",
    "np.save(\"L_mat2\",L_mat2)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a561d",
   "metadata": {},
   "source": [
    "#### Check optimization stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "X_arr_list = bayesianTools.extract_X_arr_list_from_df(df)\n",
    "dt_list = bayesianTools.extract_dt_list_from_df(df)\n",
    "\n",
    "def costFun(params):\n",
    "#     TT_stick,TT_unstick,DD,AA = params\n",
    "    DD,AA = params\n",
    "    TT_stick = T_stick\n",
    "    TT_unstick = T_unstick\n",
    "    t = time.time()\n",
    "    L = bayesianTools.multiple_trajectories_likelihood(X_arr_list, dt_list, TT_stick, TT_unstick, DD, AA,\n",
    "                                     is_parallel=False)\n",
    "    print(\"Params=[{},{},{},{}]; L={}; In {} sec\".format(\n",
    "    np.round(TT_stick,0),np.round(TT_unstick,0),np.round(DD,9),np.round(AA,9),np.round(L,9),np.round(time.time()-t,1)))\n",
    "    return -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "res = scipy.optimize.minimize(costFun, [D*2,A/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870f92d",
   "metadata": {},
   "source": [
    "#### Check that the Viterbi paths are close enough to the true paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc49ec9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_rows = int(np.ceil(N_particle/2))\n",
    "fig,ax=plt.subplots(N_rows,2)\n",
    "reload(bayesianTools)\n",
    "\n",
    "import time\n",
    "from utils import profile\n",
    "\n",
    "X_arr_list = bayesianTools.extract_X_arr_list_from_df(df)\n",
    "dt_list = bayesianTools.extract_dt_list_from_df(df)\n",
    "\n",
    "model_params = model.pack_model_params(T_stick,T_unstick,D,A,dt)\n",
    "for i in range(N_particle):\n",
    "    n = i % N_rows\n",
    "    m = int(i/N_rows)\n",
    "    X_arr = X_arr_list[i]\n",
    "    t = time.time()\n",
    "    S,XT,L_est = bayesianTools.viterbi_algorithm(X_arr,T_stick,T_unstick,D,A,dt_list[i],True)\n",
    "    est_time = np.round(time.time()-t,2)\n",
    "    fullState= [[S[j],X_arr[j],XT[j]] for j in range(N_steps)]\n",
    "\n",
    "    S_true = df[df.particle==i].state.values\n",
    "    XT_true = df[df.particle==i][[\"x_tether\",\"y_tether\"]].values\n",
    "\n",
    "    fullState_true= [[S_true[j],X_arr[j],XT_true[j]] for j in range(N_steps)]\n",
    "    L_tru = model.model_trajectory_log_probability(S_true,X_arr,model_params)\n",
    "    \n",
    "    print(\"Calculated in {} sec, L_tru = {}, L_est = {}\".format(\n",
    "    est_time,np.round(L_tru,3),np.round(L_est,3)))\n",
    "    \n",
    "    ax[n,m].plot(np.arange(N_steps),S_true,'-')\n",
    "    ax[n,m].plot(np.arange(N_steps),S,'--')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[n,m].set_title('yalla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfa089",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isclose(XT,XT_true, rtol=1e-05, atol=1e-08, equal_nan=True)) / float(N_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87babc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.prod(XT==XT,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaa7a6",
   "metadata": {},
   "source": [
    "# Display Some Graphs\n",
    "\n",
    "## Show trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13e022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startAtOrigin=False\n",
    "if startAtOrigin:\n",
    "    plotly_df=trajAnalysis.shift_traj_to_origin(df)\n",
    "else:\n",
    "    plotly_df = df.copy()\n",
    "plotly_df.y *=-1\n",
    "plotly_df[\"particle_state\"] = plotly_df.particle.astype(str)+\"_\"+plotly_df.state.astype(str)\n",
    "fig = px.line(plotly_df, x=\"x\", y=\"y\", color='particle_state',hover_data=['frame'],color_discrete_sequence=px.colors.qualitative.D3,)\n",
    "fig.update_yaxes(scaleanchor = \"x\",scaleratio = 1,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f108eb",
   "metadata": {},
   "source": [
    "## Trajectories Animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb798ea8",
   "metadata": {
    "scrolled": false,
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "reload(displayData)\n",
    "max_frame = 51\n",
    "startAtOrigin=True\n",
    "doneTrajNoMarker=True\n",
    "dispLegend=False\n",
    "if \"Traj_fig\" in locals() : plt.close(Traj_fig)\n",
    "Traj_fig, Traj_ax = plt.subplots(figsize=(5,5))\n",
    "drawnLines=displayData.plot_trajectories(df,curParticlePivotSize=5., t_end=max_frame, doneTrajNoMarker=doneTrajNoMarker,startAtOrigin=startAtOrigin,dispLegend=False, ax=Traj_ax, useDrawnLines=False, drawnLines=[],hideLines=True,axForVelocityPlot=[],particlesForFixedColoring = [])\n",
    "def animateTraj(t_end):\n",
    "    displayData.notebook_animate_traj(df,Traj_ax,t_end,max_frame,startAtOrigin=startAtOrigin,doneTrajNoMarker=doneTrajNoMarker,dispLegend=dispLegend,useDrawnLines=True,drawnLines=drawnLines,fps=0.,axForVelocityPlot=[],particlesForFixedColoring=[],curParticlePivotSize=5.)\n",
    "ani = animation.FuncAnimation(Traj_fig, animateTraj, frames=max_frame); clear_output(wait=True); HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79108896",
   "metadata": {},
   "source": [
    "## MSD Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec23768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "default_groupby = \"experiment\"\n",
    "if \"MSD_fig\" in locals() : plt.close(MSD_fig)\n",
    "MSD_fig, MSD_ax = plt.subplots(figsize=(6, 4))\n",
    "@interact(Log_Scale=True,group_by=[\"experiment\",\"particle\"],max_lagtime=(100,2000,10),N_sample_points = (2,101,1),equal_weight_per_particle=True)\n",
    "#def update(group_by=\"experiment\",Log_Scale=True,equal_weight_per_particle=True,step_lagtime=5,max_lagtime=100,):\n",
    "def update(group_by=default_groupby,Log_Scale=False,equal_weight_per_particle=True,N_sample_points=21,max_lagtime=1000,):\n",
    "    MSD_ax.cla()\n",
    "    displayData.plot_MSD(df,isdfPadded=True, lagtime=np.unique(np.round(np.logspace(0,np.log10(max_lagtime),N_sample_points))), group_by=group_by, logscale=Log_Scale, ax=MSD_ax,eqParticleWeight=equal_weight_per_particle)\n",
    "    MSD_ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b085c",
   "metadata": {},
   "source": [
    "## Displacement Distribution $G(\\Delta x,\\Delta t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a21ead",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up plot\n",
    "if \"G_fig\" in locals() : plt.close(G_fig)\n",
    "G_fig, G_ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "dt_default = 3\n",
    "xlim_default = 5.\n",
    "\n",
    "@interact(dt=(1, min(200,df.frame.max()-1), 1),semiLogScale=True,direction=[\"xy\", \"x\", \"y\"],group_by=[\"experiment\",\"particle\"],x_lim=(1., 30., 0.5),equal_weight_per_particle=True, clearAxes = True)\n",
    "def update(dt=dt_default,x_lim=xlim_default,group_by=\"experiment\",direction=\"xy\",semiLogScale=True,equal_weight_per_particle=True,clearAxes = True):\n",
    "    if clearAxes: G_ax.cla()        \n",
    "    displayData.plot_G_dx_dt(df\n",
    "                             ,isdfPadded=True, direction=direction, group_by=group_by, dt=dt, return_stats=False,semilogscale=semiLogScale,ax=G_ax,equal_particle_weight=equal_weight_per_particle)\n",
    "    G_ax.set_xlim([-x_lim,x_lim])\n",
    "    G_ax.set_ylim([1e-6,1e1]) if semiLogScale else G_ax.set_ylim([0,2.])   \n",
    "    G_ax.grid(True)\n",
    "    \n",
    "#     sns.move_legend(G_ax,\"lower left\")\n",
    "#     plt.setp(G_ax.get_legend().get_texts(), fontsize='7')  # for legend text\n",
    "#     plt.setp(G_ax.get_legend().get_title(), fontsize='8')  # for legend title\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
